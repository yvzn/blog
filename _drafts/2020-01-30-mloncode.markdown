---
title: "Machine Learning sur du code source"
date: 2020-02-26 00:00:00 +001
layout: post
author: Yvan Razafindramanana
license: CC-BY-SA-4.0
series: machine-learning-on-code
---

<acronym title="En résumé... (Too long; Didn't Read)">TL;DR</acronym> Lancer des algorithmes de machine learning sur son code source permet d'extraire des informations sur la structure des projets et d'améliorer l'outillage de développement. Ce sont les méthodes inspirées du traitement automatique du langage naturel qui semblent donner les premiers résultats. Des briques open-source comme [Gitbase](https://github.com/src-d/gitbase) ou [Babelfish](https://doc.bblf.sh/) permettent de faciliter les étapes de collection et d'analyse de la donnée. Dans ce premier article, je décris l'approche utilisée et les étapes à réaliser.

<!--more-->

Cet article est le compte-rendu d'un codelab très instructif, organisé par Alex Bezzubov et Hugo Mougard de [_source{d}_](https://sourced.tech/) lors du DevFest Nantes 2019. En guise d'introduction, vous pouvez consulter le [code source du codelab](https://github.com/mloncode/devfest2019-workshop) ainsi que les [slides de la présentation](https://docs.google.com/presentation/d/1vF0JMagmXXzn-h-OaJu6CsDt78oSQSg58YFJsBUaHxk/edit). D'autres collaborateurs de _source{d}_ ont également proposé une [conférence en anglais](https://www.youtube.com/watch?v=6NhQIaJfWXk) dont voici [les slides associés](https://egorbu.github.io/usedata_2019/). J'ai enfin réalisé une présentation pour débriefer le codelab avec mes collègues. Et si la qualité de capture vidéo n'est pas au rendez-vous, mais vous pouvez néanmoins la [visualiser sur Youtube](https://www.youtube.com/watch?v=0R7GIT4GPNk).

# Objectifs

Le _MLonCode_ (Machine Learning on source code) est un domaine assez récent mais pour lequel l'intérêt est croissant. Depuis 2-3 ans, les publications des grands acteurs de l'infomatique se multiplient (Microsoft, Google, Facebook) et on trouve de plus en plus conférences sur le sujet.

Le principe de lancer des algorithmes de machine learning sur du code source a plusieurs applications intéressantes. Par exemple, comprendre l'organisation de ses programmes, extraire des métriques évoluées et identifier des patterns ou des anti-patterns (code commun, répétitions, ...) .

Autre application, améliorer l'outillage, les environnements de développement, les compilateurs ou les logiciels de déploiement. Cette approche est par exemple actuellement mise en oeuvre par Microsoft avec _IntelliCode_, dont la promesse est de fournir une meilleure auto-complétion, contextualisée en fonction du projet et des habitudes des développeurs ou de faire des propositions de refactoring plus pertinentes.

# Approches

Plusieurs approches sont possibles pour attaquer le problème. Celle proposée par le codelab part du postulat que la formulation du code source _imite_ le langage naturel (ou <acronym title="Langage Naturel">LN</acronym>).

C'est un _a priori_ assez fort mais qui a du sens vu la manière dont le code est écrit. En effet, les identifiants de variables et de méthodes sont généralement choisis de manière à décrire le comportement attendu de façon compréhensible par un être humain. De même, les mots clés logiques (`if...then`, `for`, etc.) permettent de structurer le code afin qu'il soit lisible comme une suite de phrases à peu près _naturelles_.

Donc en considérant le code source comme une séquence de mots avec une signification logique, cette approche a l'avantage de pouvoir réappliquer les patterns statistiques et modèles de machine learning déja connus en traitement du langage (<acronym title="Traitement Automatique du Langage Naturel">TALN</acronym> ou en anglais <acronym title="Natural Language Processing">NLP</acronym>).

Elle a aussi ses limites, dans la mesure où elle ne tient compte que des mots en eux-mêmes, sans tirer profit de toute la structure sous-jacente, (méthodes, branchements, regroupements logiques, ...), qui est malgré tout une part importante de l'information portée par le code.

# Etapes

Les animateurs de l'atelier proposent un sommaire calqué sur les étapes habituellement mises en oeuvre dans les projets de _data science_:

1. Définir le problème
2. Collecter la donnée
3. Analyser la donnée
4. Evaluer les résultats
5. Communiquer

Cette organisation permet d'aborder, dans l'ordre, chacune des tâches liés à la conception et à la validation d'un modèle de machine learning.

Comme exemple de problèmes à résoudre, les travaux pratiques se font autour de deux sujets, plutôt accessibles en théorie:
- Détecter dans une codebase les projets similaires (afin, par exemple, de les regrouper par thème: sécurité, gestion de données, interfaces, ...)
- Suggérer algorithmiquement le nom d'une méthode à partir de son corps (son contenu)

# Collecter la donnée

La première étape est donc de récupérer le code source sur lequel travailler. Un énorme avantage dans ce domaine, c'est de disposer d'une très grande source de données, librement accessibles et téléchargeables: [Github](https://github.com). Le codelab propose de se concentrer sur une organisation en particulier, _intéressante_ pour la variété des sujets abordés et la quantité d'informations disponibles : Apache.

Github propose une API publique qui peut être requêtée afin de récupérer la liste des organisations et la liste des dépôts de code associés. C'est un bon point de départ, néanmoins la récupération des données pose quelques problèmes de performance (temps de téléchargement) et de stockage (taille des fichiers sur le disque dur). Pour aller plus vite, la recherche est donc limitée aux dépôts _populaires_, c'est à dire avec un nombre minimum de favoris et en évitant les dépôts les plus gros, certains dépôts d'Apache étant vraiment volumineux.

Ces restrictions prises en compte, il s'agit maintenant :
- de télécharger le code en tant que tel (avec `git clone` / `git checkout`)
- de paralléliser ces téléchargements pour gagner du temps
- de filtrer et de nettoyer les dépôts

L'étape de filtrage est nécessaire car les dépôts contiennent en général, en plus du code source, des fichiers de configuration, des librairies tierces... qui sont peu intéressantes pour l'analyse. Il s'agit de supprimer, par exemple:
- les fichiers de configuration (_protobuf_, _settings_, ...)
- les répertoires `vendors`
- etc.

Une fois le code récupéré localement, on peut parcourir l'arborescence des répertoires, de lire les fichiers un par un et de consulter l'historique git en ligne de commande. C'est en réalité plutôt fastidieux et une approche plus pragmatique est proposée, utilisant un outil open-source développé par _source{d}_: [Gitbase](https://github.com/src-d/gitbase).

Cet outil permet de charger automatiquement le contenu des dépôts, de les exposer comme une base de données et d'en simplifier l'exporation via des requêtes SQL. Voici par exemple un apercu des tables du modèle Gitbase utilisées pour le codelab :

![modèle de données simplifié Gitbase](https://raw.githubusercontent.com/mloncode/devfest2019-workshop/master/notebooks/img/tables.png)

Gitbase permet ainsi de travailler plus rapidement et plus efficacement qu'en allant parcourir manuellement tous les fichiers de tous les dépôts. On dispose grâce à Gitbase d'une structure organisée permettant d'explorer l'arborescence en lançant des recherches dans une base de données. Il s'agit maintenant d'analyser le contenu des fichiers, le code en lui-même.

# Analyser la donnée 

Le code source étant présenté sous forme de fichiers texte, il est possible de le traiter comme un flux des caractères qu'on peut parser pour extraire l'information, par exemple avec des expressions régulières ou des machines à état. C'est un travail assez long et surtout, il faut décliner les expressions régulières pour chacun des langages de programmation potentiellement recontrés dans les dépôts (Java, Python, JS, etc.)

L'outil [Babelfish](https://doc.bblf.sh/) facilite la mise en oeuvre de cette étape. Il permet de construire un arbre syntaxique (ou <acronym title="Abstract Syntax Tree">AST</acronym>) qui est une représentation logique de la structure d'un fichier source. Cet arbre syntaxique peut ensuite être parcouru avec des requêtes _XPath_, ce qui permet d'extraire directement les infomations pertinentes (par exemple, les noms de variables, les méthodes, etc.).

![capture d'écran Babelfish](https://github.com/yvzn/bbl-mloncode/raw/master/resources/babelfish.png)

De plus Babelfish supporte nativement une quinzaine de langages de programmation parmi les plus populaires, c'est une tâche de moins à réaliser. Enfin, l'équipe de Gitbase a mis en place une inter-opérabilité avec Babelfish, permettant de lancer les recherches _XPath_ directement sur le contenu indexé par la base de données.

On dispose ainsi grâce à Babelfish d'une donnée structurée permettant de parcourir, via des requêtes _XPath_, le contenu syntaxique de l'ensemble des fichiers préalablement récupérés.

# Concevoir le modèle

Le premier exercice du codelab consiste à détecter les projets similaires entre eux. Partant de l'hypothèse que la formulation du code source _imite_ le langage naturel, les animateurs proposent d'utiliser les identifiants de variables, de méthodes, de packages, etc. pour regrouper les projets par thématique. Une intuition de ce principe pourrait être : deux projets contenant les identifiants _open_, _connexion_, _socket_, _send_, etc. dans des proportions similaires ont de fortes chances d'être liés à la même thématique, qu'on pourrait par exemple appeler _communication réseau_. 

Babelfish et Gitbase permettent d'extaire les identifiants de tous les fichiers source d'un projet, en combinant requêtes SQL et _XPath_. Cependant si on utilise directement les identifiants tels quels, le vocabulaire produit est beaucoup trop grand pour être analysé. En effet les identifiants dans un programme consistent souvent en une combinaison de mots, par exemple `tcp_socket_connect` ou `get_remote_address`. Le nombre de combinaisons est donc quasiment illimité et il devient difficile de trouver des similarités. On donne, à titre de comparaison, la taille du vocabulaire russe qui contient environ 150.000 mots, le japonais environ 500.000 mots, les animateurs estiment celui de tous les identifiants informatiques à 49 millions de mots.

Une solution peut être de décomposer les identifiants en mots unitaires, pour réduire le vocabulaire. Par exemple `tcp_socket_connect` est transformé en liste `[tcp, socket, connect]`. Cela permet de réduire la taille du vocabulaire à des valeurs raisonnables. Les identifiants les plus rares (les moins fréquents) sont également enlevés.

Un modèle d'apprentissage non supervisé permet de constuire automatiquement les thématiques à partir des identifiants. En l'occurence le modèle mis en place s'appelle le _topic modeling_. C'est un modèle statistique qui va essayer de compter et regrouper les identifiants qui apparaissent souvent ensemble dans les mêmes fichiers. Ces regroupements d'identifiants sont ensuite utilisés par le modèle pour définir un _topic_.

Il est important de faire remarquer ici que cette notion de _topic_ est complètemet abstraite pour le modèle. Ainsi, s'il est capable de se rendre compte que certains mots apparaissent souvent ensemble, il ne sait en revanche pas apporter de _signification_ aux _topics_ ainsi découverts. Il va les nommer arbitrairement `topic_1`, `topic_2`, etc. Ce sera à nous de mettre une étiquette sur ces ensembles de mots. 

![Exemple de topics extraits à partir d'identifiants (extrait)](https://github.com/yvzn/bbl-mloncode/raw/master/resources/topics_vs_identifiers.png)

# Créer le modèle 

L'outil [BigARTM](http://bigartm.org/) permet de faire du _topic modeling_ en analysant le code source. Il faut lui fournir en entrée le nombre de topics souhaités et il va construire automatiquement le modèle d'apprentissage à partir des identifiants. Il peut ensuite fournir pour chaque fichier une liste de scores, représentant la proximité de ce fichier avec chacun des _topics_ identifiés.

Les animateurs du codelab proposent néanmoins d'ajuster légèrement le résultat fourni par l'outil. Le _sparsing_ consiste à supprimer (c'est à dire donner un score de 0) les topics ayant obtenu des scores déjà très faibles. Cela rend le modèle plus simple à interpréter de manière globale, en minimisant le nombre de topics à prendre en compte et le bruit généré par cette information peu significative.

# Evaluer les résultats

La généralisation du traitement consiste à extraire une moyenne de tous les topics de tous les fichiers d'un même projet. On peut alors calculer une distance entre les projets et regarder pour chaque projet les projets les plus proches. Cela donne une idée de similarité entre projets suivant une thématique.

En utilisant `git blame` (via _GitBase_) on peut également identifier les développeurs qui ont édité tel ou tel fichier et, par extrapolation, en déduire les _topics_ sur lesquels chacun a pu travailler. On peut alors également calculer une distance entre développeurs, qui donne une idée des développeurs travaillant sur les mêmes thématiques.

Puisqu'il s'agit des mêmes _topics_ que pour les projets, on peut également calculer une distance entre développeurs et projets, ce qui permet d'identifier les projets ayant les mêmes thématiques que celles sur lesquelles un développeur travaille habituellement.

Le dernier outil présenté, [pyLDAvis](https://github.com/bmabey/pyLDAvis), permet de visualiser graphiquement les topics générés par BigARTM et de comparer la distance entre _topics_ et entre projets.

![Topics visualisés via pyLDAvis](https://github.com/yvzn/bbl-mloncode/raw/master/resources/pyldaviz.png)

# Conclusion

Par manque de temps, nous n'avons pas pu aborder le second sujet qui consistait à suggérer algorithmiquement le nom d'une méthode à partir de son corps. Pour résumer, les animateurs nous ont indiqué utiliser des modèles de traduction automatisée (comme [OpenNMT](https://opennmt.net/) et [seq2seq](https://google.github.io/seq2seq/)) pour aborder cette problématique, et nous ont redirigé vers le [code source du codelab](https://github.com/mloncode/devfest2019-workshop).

Cet atelier m'a donc permis de m'initier au _MLonCode_ (Machine Learning on source code) dont l'approche inspirée du _Natural Language Processing_ permet d'extraire des métriques de sa codebase. Il a repris méthodiquement les principales étapes d'un projet de data science, ce qui permet de constater que la majorité du travail consiste à collecter la donnée (le code source) et à la formatter / à la nettoyer pour la rendre exploitable. Il a également mis l'accent sur le fait qu'il existe de nombreux outils pour se faciliter la tâche et qu'il ne faut pas hésiter à les utiliser.
